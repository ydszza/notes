## 1. CPU是如何执行程序的？

### 1.1 图灵机的工作方式
**图灵机的组成**
- 有一条【纸带】，纸带由一个个连续的格子组成，每个格子可以写入字符，纸带 = 内存，纸带上的格子的字符好比内存中的数据和程序。
- 有一个【读写头】，读写头可以读取纸带上任意格子的字符，也可以吧字符写入到纸带的格子上；
- 读写头有一些部件，比如存储单元、控制单元以及运算单元：
    - 存储单元用于存放数据
    - 控制单元用于识别字符是数据还是指令，以及控制程序的流程等
    - 运算单元用于执行运算指令

**图灵机执行流程**
比如简单数字运算`1+2`
- 首先，用读写头吧【1、2、+】这3个字符写入到纸带上的3个格子，然后读写头先停在1字符对应的格子上
- 接着，读写头读入1到存储设备中，这个存储设备成为图灵机的状态
- 然后，读写头向右移动一个格，用同样的方式把2读入到图灵状态机，于是现在图灵机的状态存储了两个连续的数字1、2
- 读写头再往右移动一个格，遇到了+号，读写头读入+号后传输给【控制单元】，控制单元发现这是一个+号不是数字，就不存入状态中，而是通知【运算单元】工作，运算单元吧1和2读入并计算，再将计算的结果3存入状态
- 最后，运算单元将结果返回给控制单元，控制单元将结果头传输给读写头，读写头将3写入到纸带的格子上

### 1.2 冯诺依曼模型
- 定义计算机基本结构为5个部分：**运算器、控制器、存储器、输入设备、输出设备**，称为冯诺依曼模型。
```
------------------------------
|          Memory            |
------------------------------
  |    |           |      |
-----------      ---------------
|         |       | Arithmetic |
| Control |       |    Logic   |
|  Unit   |       |    Unit    |
|         |       | Accumulator|
-----------      ---------------
                     /      \
                    /        \
              ---------   -----------
              | Input |   | Output  |
              ---------  ------------
```

- 运算器、控制器是在中央处理器单元里的，存储器就是我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘，显示器
- 存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。
- 内存：程序和数据存储在内存中，存储的区域是线性的。
- 中央处理器：中央处理器也就是CPU，32位和64位是CPU的最主要区别在于一次能计算多算字节数据（CPU位宽）
    - 32位CPU一次可以计算4字节
    - 64位CPU一次可以计算8字节
    - CPU内部还有一些组件，如常见的寄存器、控制单元和逻辑运算单元等，其中控制单元负责CPU工作，逻辑运算单元负责计算，而寄存器可以分为多种类型，每种寄存器功能又不尽相同
    - 常见寄存器：通用寄存器-》存放需要计算的数据；程序计数器-》用来存储CPU要执行的下一条指令【的内存地址】;指令寄存器-》用来存储程序计数器指向的指令
- 总线：用于CPU和内存以及其他设备之间的通信，可分为三种：
    - 地址总线：用于指定CPU要操作的内存地址
    - 数据总线：用于读取内存的数据
    - 控制总线：用于发送和接收信号，如中断信号，复位信号等
- 输入输出设备：输入设备向计算机输入数据，计算机计算后吧数据输入到输出设备

### 1.3 线路位宽和CPU宽度
- 线路位宽指一次能够传输的位数
- CPU位宽
- 如果计算的数额不超过32位数字的情况下，32位和64位CPU之间没有什么区别，只有当计算超过32位数字情况下，64位的优势才能体现出来。

### 1.4 程序执行的基本过程
冯诺依曼模型执行流程
```
---------------------------------
|                                |
|  ---------      ------------   |
|  | 寄存器 |      | 控制单元  |    |
|  | 寄存器 |      |          |    | 
|  | 寄存器 |      | 指令寄存器 |\  |
|  | ..... |      | 程序计数器 |  \|
|  ---------      ------------   |\
|                                |  \   
|  --------------                |   指令....
|  | 逻辑运算单元 |                |
|  --------------                |
|                                |
|         CPU                    |
----------------------------------
```
CPU执行程序的过程如下：
- 第一步，CPU读取【程序计数器】的值，这个值是指令的内存地址，然后CPU的【控制单元】操作【地址总线】指定访问内存的地址，接着通知内存设备准备数据，数据准备好之后通过【数据总线】将指令数据传给CPU，CPU收到内存传来的数据后，将这个指令存到【指令寄存器】
- 第二步，CPU分析【指令寄存器】的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给【逻辑运算单元】运算，如果是存储指令，则交由【控制单元】执行
- 第三步，CPU执行完指令后，【程序计数器】的值自增，表示指向下一条指令。这个自增的大小由CPU的位宽决定，比如32位CPU指令为4字节，因此【程序计数器】的值会自增4

CPU循环从程序计数器读取指令，执行。然后下一条指令，不断循环，直到程序执行结束，这个循环过程称为**CPU的指令周期**


### 1.5 a=1+2的具体执行过程
首先CPU不认识a=1+2这个字符串，需要汇编器翻译成机器码  
......   
现在大多数CPU都使用流水线的方式执行指令，所谓流水线即把一个任务拆分成多个小任务，于是一个指令通常有四个阶段，称为4级流水线：
- Fetch：CPU通过 程序计数器读取对应内存的指令，【取得指令】
- Decode：CPU对指令进行解码，【指令译码】
- Execute：CPU执行这个指令，【指令执行】
- Store：CPU将计算结果存回寄存器或将寄存器的值存入内存，【数据回写】
上述4个阶段，称为指令周期，CPU的工作就是一个周期接一个周期的周而复始 

实际上不同的阶段其实由不同的组件完成：
- 取得指令阶段，指令放在【存储器】里，实际上，通过程序计数器和指令寄存器取出指令的过程由【控制器】操作的
- 指令译码的过程，也是由【控制器】进行的
- 指令执行的过程，无论是算术操作还是逻辑操作或者数据传输、条件分支操作，都是由【算术逻辑单元】操作的，也就是由【运算器】处理的，但是如果是一个简单的无条件地址跳转，则直接在【控制器】里完成，无需运算器

指令的类型：
- 数据传输指令：如store/load是寄存器与内存间数据传输的指令，mov是将一个内存地址的数据移动到另一个内存地址的指令
- 运算类型的指令：如加减乘除，位运算、比大小等，他们最多只能处理两个寄存器中的数据；
- 跳转类型的指令：通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的if-else/switch-case、函数调用等等
- 信号类型指令：比如发生中断的指令trap
- 闲置类型的指令：比如指令nop，执行后CPU空转一个周期

CPU的执行速度：  
- CPU的硬件参数GHz，如1GHz，指时钟频率1G，代表一秒会产生1G次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期  
- 一个时钟周期，CPU可以完成一个最基本的动作，时钟频率越高，时钟周期越短，工作速度越快
- 一个时钟周期不一定能完成一条指令，大多数指令不能在一个周期完成，通常需要若干个周期。不同的指令时钟周期可能不同。如乘法和加法都是一条指令，但是乘法需要的时钟周期比加法多
- 程序的CPU执行时间 = CPU时钟周期数 \* 时钟周期时间
程序的CPU执行时间 = 指令数 \* CPI(每条指令的平均时钟周期) \* 时钟周期时间
- 程序优化方向：指令数、指令的平均时钟周期数、时钟周期时间


## 2. 磁盘比内存满几万倍？
### 2.1 存储器的层次结构
- 寄存器 > CPU L1、L2、L3 cache > 内存 > SSD/HDD硬盘
- CPU cache 分为L1/L2/L3三层，其中L1 Cache通常分为【数据缓存】【指令缓存】
- 存储器，速度越快，能耗越高，材料越贵、以至于越快的存储器容量越小
- CPU cache 使用SRAM（静态随机存储器）芯片
```
CPU
                    核心1                         核心2
L1 cache    L1数据缓存   L1指令缓存         L1数据缓存   L1指令缓存

------------------------------------------------------------------------------------------------------

L2 cache            L2缓存                        L2缓存
------------------------------------------------------------------------------------------------------

L3 cache                           L3缓存

                                   内存
```
- L1高速缓存：访问速度和寄存器一样快，通常只需要2~4个时钟周期，而大小在及时KB到几百KB不等。  
每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成指令缓存和数据缓存。  
在Linux下，通过命令查看CPU L1 cache 
```
//【L1 Cache 「数据」 缓存的容量大小
$ cat /sys/devices/system/cpu/cpu0/cache/index0/size
32K

查看 L1 Cache 「指令」缓存的容量大小，则是：
$ cat /sys/devices/system/cpu/cpu0/cache/index1/size
32K
```
- L2高速缓存：同样每个CPU都有，但L2位置比L1离CPU远，大小比L1高速缓存大，CPU型号不同则大小不同，访问速度更慢，在10~20个时钟周期  
Linux上查看CPU的L2 cache 容量大小
```
cat /sys/devices/system/cpu/cpu0/cache/index2/size
256K
```
- L3高速缓存：通常多个核心共用，位置比L2高速缓存离CPU核心更远，大小也会更大，通常在几MB到几十MB不等，大小根据CPU型号决定，访问速度约在20~60个时钟周期
在 Linux 系统，我们可以通过这条命令，查看 CPU 里的 L3 Cache 的容量大小：
```
$ cat /sys/devices/system/cpu/cpu0/cache/index3/size 
3072K
```
- 内存：使用与cache不同的DRAM（动态随机存储器）芯片，相比之下密度更高，功耗更低，容量更大，造价便宜。速度大概在200~300个时钟周期之间
- SSD/HDD硬盘：  
SSD（solid-State disk）固态硬盘，结构与内存类似，相对于内存的优点是断点后数据还存储。内存的读写比SSD大概快10~1000倍  
HDD（hard disk drive）机械硬盘，通过物理读写的方式来访问数据，比内存慢10w倍左右

### 2.2 存储器的层次结构
- 每个存储器只和相邻的一层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量  
- 当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据

| 存储器   | 硬件介质    | 单位成本（美元） | 随机访问延时 |
| -------- | ----------- | ---------------- | ------------ |
| L1 Cache | SRAM        | 7                | 1ns          |
| L2 Cache | SRAM        | 7                | 4ns          |
| Memory   | DRAM        | 0.015            | 100ns        |
| Disk     | SSD（NAND） | 0.0004           | 150ns        |
| Disk     | HDD         | 0.00004          | 10ms         |

- 那机械硬盘、固态硬盘、内存这三个存储器，到底和 CPU L1 Cache 相比速度差多少倍呢？
    - CPU L1 cache 随机访问延时1ns，内存则是100ns，所以CPU L1 cache比内存快100倍
    - SSD的访问延时是150us，所以CPU L1 Cache 比SSD快15000倍左右
    - 最慢的机械硬盘随机访问延时已经高达 10 毫秒，我们来看看机械硬盘到底有多「龟速」
    - SSD 比机械硬盘快 70 倍左右；
    - 内存比机械硬盘快 100000 倍左右；
    - CPU L1 Cache 比机械硬盘快 10000000 倍左右


## 3. 如何写成让CPU跑得更快的代码？
### 3.1程序执行时
- 会先将内存中的数据加载到共享的 L3 Cache 中，
- 再加载到每个核心独有的 L2 Cache，
- 最后进入到最快的 L1 Cache，
- 之后才会被 CPU 读取。
### 3.2 越靠近 CPU 核心的缓存其访问速度越快，
- CPU 访问 L1 Cache 只需要 2~4 个时钟周期，
- 访问 L2 Cache 大约 10~20 个时钟周期，
- 访问 L3 Cache 大约 20~60 个时钟周期，
- 而访问内存速度大概在 200~300 个 时钟周期之间。
| 部件     | CPU访问所需时间   |
| -------- | ----------------- |
| L1 Cache | 2~4个个时钟周期   |
| L2 Cache | 10~20个时钟周期   |
| L3 Cache | 20~60个时钟周期   |
| 内存     | 200~300个时钟周期 |
### 3.3 CPU Cache的数据结构和读取过程：
- CPU Cache的数据是从内存读取的，是以一块一块的方式读取的，而不是按照单个数组元素来读取的，在这一块一块的数据数据，称为cache line（缓存块）
- Linux系统CacheLine查看：
```
$ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size 
64
```
- 比如，有一个 int array[100] 的数组，当载入 array[0] 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会顺序加载数组元素到 array[15]，意味着 array[0]~array[15] 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。
- 事实上，CPU 读取数据的时候，无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据。

#### CPU如何读取内存的数据：直接映射cache
- 由于CPU访问内存数据是一块一块读取的，具体大小取决于CacheLIne的大小，在内存中，这一块数据称为数据块，读取时要拿到数据所在内存块的地址
- 对于直接映射cache策略，就是把内存块的地址时钟映射在一个CacheLine地址，映射关系使用【取模运算】，取模运算的结果就是内存块地址对应的CacheLine的地址
- 如，内存划分32个内存块，CPU cache共8个CacheLine，假设CPU要访问15号内存块，除了15号内存块映射在7号CacheLine，还有23号，31号内存块都是映射在7号CacheLine
- 此方式会出现多个内存块对应一个CacheLine，因此CacheLine还会存储一个【组标记】，这个组标记记录当前CacheLine存储的数据对应的内存块，以此区分不同的内存块。
- 除了组标记，CacheLine还存储两个信息：
    - 从内存加载过来的实际存放【数据】
    - 【有效位】，标记对应的CacheLine中的数据是否有效，无效的话需要从CPU从新加载数据
- CPU从CacheLine中读取数据，并不读取整个数据块，而是读取需要的片段，即一个字，通过在CacheLine中进行【偏移】来读取
- 因此一个内存访问，包括组标记、CacheLine索引，偏移量三种信息

#### 当内存数据在CPU cache中，CPU访问一个内存地址的4个步骤
- 1. 根据内存地址索引信息计算CacheLine的索引，找到CacheLine的地址
- 2. 判断CacheLine中的有效位，确认数据有效，无效则访问内存，从新加载数据
- 3. 对比内存地址中和CacheLine的组标记，确认CacheLine的数据为需要访问的内存数据，不是的话CPU访问内存加载数据
- 4. 根据内存地址中的偏移量，从CacheLine的数据中读取对应的字

#### 除了直接映射策略，还有其他策略，如全相连cache、组相连cache等

### 3.4 如何写成让CPU跑的更快的代码
**核心：提高缓存的命中率**

#### 3.4.1 如何提升数据缓存命中率
- 遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升

#### 3.4.2 如何提升指令缓存命中率
- CPU 的【分支预测器】：对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快。
- C/C++ 语言中编译器提供了 likely 和 unlikely 这两种宏，如果 if 条件为 ture 的概率大，则可以用 likely 宏把 if 里的表达式包裹起来，反之用 unlikely 宏。  
实际上，CPU 自身的动态分支预测已经是比较准的了，所以只有当非常确信 CPU 预测的不准，且能够知道实际的概率情况时，才建议使用这两种宏。
```
#define likely(x) __builtin_expect(!!(x), 1)
#define lunikely(x) __builtin_expect(!!(x), 0)

if (likely(a == 1))
{
    //...
}
else
{
    //....
}
```

#### 3.4.3 如何提高多核CPU的缓存命中率
- 在单核 CPU，虽然只能执行一个进程，但是操作系统给每个进程分配了一个时间片，时间片用完了，就调度下一个进程，于是各个进程就按时间片交替地占用 CPU，从宏观上看起来各个进程同时在执行。
- 现代 CPU 都是多核心的，进程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，如果一个进程在不同核心来回切换，各个核心的缓存命中率就会受到影响，相反如果进程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。
- 当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把线程绑定在某一个 CPU 核心上，这样性能可以得到非常可观的提升
- Linux提供了`sched_setaffinity`方法，实现线程绑定某个CPU核心
```
#define _GNU_SOURCE
#include <sched.h>
int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask)
```


## 4. CPU缓存一致性
### 4.1 CPU cache 数据的写入
- 随着时间推移，CPU和内存的访问速度差距越来越大 ，于是在CPU内部嵌入了CPU cache，充当CPU和内存之间的缓存角色。cache结构如前
- CPU cache包含多个CacheLine，CPU line由各种标记tag+数据块组成
- 数据不光有读操作，还有写操作，当数据写入cache后将与内存的数据不一致，于是需要进行同步
- 数据写入方法：如写直达，写回

##### 4.1.1 写直达
- 即把数据同时写入内存和cache中
- 流程：
    - 写入前判断数据是否在cache中
    - 如果数据在cache，则将数据更新到cache，再写入内存中
    - 如果数据不在cache，则直接把数据写到内存里
- 总结：写直达很直观，很简单，但是问题明显，无论数据在不在cache中，每次写操作都会写回到内存中，这样写操作非常浪费时间

##### 4.1.2 写回
由于写直达耗时大，影响性能，为此出现了写回的方法。写回机制中，当发生写操作时，新的数据仅仅被写入cache Block里，只有当修改过的cache block被替换时才需要写回到内存中，这样减少了写回内存的频率，提高系统的性能  
步骤：
- 当发生写操作，数据存在cache中，则把数据更新到cache，同时标记cache block为脏，标明数据和内存的不一致，此时不需要写回内存
- 当写操作发生，数据对应的cache block里存放了【别的内存地址的数据】的话，需要检测次cache block的数据有没有被标记为脏数据，有的话需要写回内存，，然后把当前的数据写入cache block，同时标记为脏数据，，如果没有被标记为脏数据，则直接写入到此cache block。
结论：当我们程序的cache命中率高时，大部分时间CPU不需要读取内存，性能会比写直达好



### 4.2 缓存一致性问题
#### 4.2.1 由于现在的CPU是多核的，L1和L2cache是多个核心各自独有的，因此会带来缓存一致性的问题，如果不能保证缓存的一致性问题，可能造成结果错误  
解决办法：
- 第一点：当某个CPU的核心里的cache数据更新时，需要传播到其他的cache，称为写传播
- 第二点：某个CPU核心对数据的操作顺序，必须在其他核心看起来顺序是一样的，这称为事务的串行化。  
例如，c核心收到a核心吧数据改为100，b核心把数据改为200，那么d核心也必须收到的是100再200的变化传播，称为事务的串行化
要实现事务串行化，要做到两点：
- CPU核心对于cache中数据的操作，需要同步给其他的CPU核心
- 要引入【锁】的概念，如果两个CPU核心有相同的数据的cache，那么对于cache数据的更新，只有拿到锁的才能对数据进行更新

#### 4.2.2 事务串行化的技术实现
**总线嗅探**
以i变量的修改为例，当a核心修改L1cache中i的值，通过总线把事件广播到其他的核心，然后每个CPU核心都会监听到总线上的广播事件，并检查是否有相同的数据存在自己的L1cache，如果b核心也有该数据，则把数据更新到自己的L1cache  
此方法简单，CPU需要时刻监听总线活动，但是不管别的核心cache是否有相同的数据，都要发出一个广播，加重了总线的负担  
此外，总线嗅探只能保证某个CPU的修改事件被其他的CPU核心知到，不能保证事务的串行化  
于是，有了MESI协议，基于总线嗅探机制实现事务串行化，也使用了状态机机制降低了总线带宽压力，做到了CPU缓存的一致性

**MESI协议**
4个状态：
- Modified，已修改
- Exclusive，独占
- Shared，共享
- Invalidated，已失效
这四个状态用来标记cache line四个不同的状态
- 【已修改】就是前面的脏数据标记，代表cache block数据被更新过，但是没写入内存。  
- 【已失效】状态，表示这个cache block数据失效了，不可以读取该状态的数据
- 【独占】和【共享】代表cache block的数据是干净的，即cache block的数据和内存的数据是一致的  
- 【独占】和【共享】差别在于，独占状态，数据只能存在于一个CPU核心的cache里，其他核心没有该数据，此时向独占的cache写数据，就可以自由写入，不需要通知其他CPU核心，不存在缓存一致性问题  
- 【独占】状态下，其他核心从内存读取相同数据到自己的cache时，独占状态需要改为共享状态  
- 【共享】状态代表相同的数据在多个CPU核心的cache里，当我们需要更新cache里的数据时，不能直接修改，而是先向其他CPU核心广播，要求其他CPU核心把对于的cacheline标记为【无效】状态，然后更新当前cache的数据  



## 5. CPU执行任务

### 5.1 CPU读写数据
如前文......

### 5.2 伪共享问题
为了缓存一致性，引入了MESI协议，但是当出现两个核心交替修改同一个变量时，就会出现cache失效的情况，称为【伪共享】

### 5.3 伪共享避免
- 首先应该避免多线程频繁修改同一块内存
- 实际项目避免伪共享问题：在Linux内核存在`__cacheline_aligned_in_smp`宏解决伪共享
```
//1. Linux宏
#ifdef CONFIG_SMP
#define __cacheline_aligned_in_smp __cacheline_aligned
#else
#define __cacheline_aligned_in_smp
#endif

//当在多核SMP系统中，对于连续的内存，如结构体，可以使用该宏实现CacheLine对齐
//如下，这样a和b就在两个cacheline中了
struct test
{
    int a;
    int b __cacheline_aligned_in_smp;
};

//2. 前置填充或后置填充
//由于「前后」各填充了 7 个不会被读写的 long 类型变量，所以无论怎么加载 Cache Line，这整个 Cache Line 里都没有会发生更新操作的数据，
//于是只要数据被频繁地读取访问，就自然没有数据被换出 Cache 的可能，也因此不会产生伪共享的问题。
class test
{
    int a;
    long b,c,d,e,f,g;
    int b1,c1,c1,d1,e1,f1,g1,
    int a1;
};
```

### 5.3 CPU如何选择线程
5.3.1 在Linux内核中，进程和线程都是`task_struct`结构体表示的
- 区别在于线程的task_struct结构体里部分资源是共享了进程已创建的资源，比如内存地址地址空间，代码段，文件描述等，所以Linux的线程也称为轻量级进程，因为线程的task_struct比进程的承载的资源少
- 一般而言，没有创建线程的进程，是只有单个执行流，称为主线程，如果想让进程处理更多的事情，可以创建多个线程分别去处理，但是对应的都是内核里的task_struct
- linux内核调度器，调度对象是task_struct,称为任务
    - 实时任务：对系统的响应时间要求很高，也就是尽可能快的执行实时任务，优先级在0-99内算实时任务
    - 普通任务：响应时间没有很高的要求，优先级100-139范围内都是普通任务

5.3.2 调度类
Linux为了保障高优先级的任务尽可能的早被执行，于是分为以下几种调度器
| 调度类   | 调度器         | 调度策略                      | 运行队列 |
| -------- | -------------- | ----------------------------- | -------- |
| Dealine  | Deadline调度器 | SCHED_DEADLINE                | dl_rq    |
| Realtime | RT调度器       | SCHED_FIFO<br />SCHED_RR      | rt_rq    |
| Fair     | CFS调度器      | SCHED_NORMAL<br />SCHED_BATCH | cfs_rq   |
- Deadline和Realtime这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来有三种，作用如下：
    - SCHED_DEADLINE：按照deadline进行调度，距离当前时间点最近的deadline的任务会被优先调度
    - SCHED_FIFO：对于相同优先级的任务，按照先来先服务的原则，但是优先级更高的任务，可以抢占优先级低的任务，也就是优先级高的任务可以【插队】
    - SCHED_RR：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片后会被放在队列尾，以保证相同的优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务
- Fair调度类是应用于普通任务，都是由CFS调度器管理的，分为两种调度策略：
    - SCHED_NORMAL：普通任务使用的调度策略
    - SCHED_BATCH：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低他的优先级

5.3.3 完全公平调度
- 我们平日遇到的都是最基本的普通任务，对于普通任务，公平性最主要，在Linux里面实现了一个基于cfs的调度算法，也就是完全公平调度
- 算法的理念是想让分配给每个任务的 CPU 时间是一样，于是它为每个任务安排一个虚拟运行时间 vruntime，如果一个任务在运行，其运行的越久，该任务的 vruntime 自然就会越大，而没有被运行的任务，vruntime 是不会变化的。  
在 CFS 算法调度的时候，会优先选择 vruntime 少的任务，以保证每个任务的公平性。  
这就好比，让你把一桶的奶茶平均分到 10 杯奶茶杯里，你看着哪杯奶茶少，就多倒一些；哪个多了，就先不倒，这样经过多轮操作，虽然不能保证每杯奶茶完全一样多，但至少是公平的
- 上面提到的例子没有考虑到优先级的问题，虽然是普通任务，但是普通任务之间还是有优先级区分的，所以在计算虚拟运行时间 vruntime 还要考虑普通任务的权重值，注意权重值并不是优先级的值，内核中会有一个 nice 级别与权重值的转换表，nice 级别越低的权重值就越大  
`虚拟运行时间vruntime += 实际运行时间delta_exec * NICE_0_LOAD/权重`

5.3.4 CPU运行队列
- 一个系统通常都会运行着很多任务，多任务的数量基本都是远超 CPU 核心数量，因此这时候就需要排队。
- 事实上，每个 CPU 都有自己的运行队列（Run Queue, rq），用于描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列，Deadline 运行队列 dl_rq、实时任务运行队列 rt_rq 和 CFS 运行队列 csf_rq，其中 csf_rq 是用红黑树来描述的，按 vruntime 大小来排序的，最左侧的叶子节点，就是下次会被调度的任务。
- 这几种调度类是有优先级的，优先级如下：Deadline > Realtime > Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 dl_rq 里选择任务，然后从 rt_rq 里选择任务，最后从 csf_rq 里选择任务。因此，实时任务总是会比普通任务优先被执行。

5.3.5 调整优先级
如果我们启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务，普通任务的调度类是 Fail，由 CFS 调度器来进行管理。CFS 调度器的目的是实现任务运行的公平性，也就是保障每个任务的运行的时间是差不多的。

如果你想让某个普通任务有更多的执行时间，可以调整任务的 nice 值，从而让优先级高一些的任务执行更多时间。nice 的值能设置的范围是 -20～19， 值越低，表明优先级越高，因此 -20 是最高优先级，19 则是最低优先级，默认优先级是 0。

是不是觉得 nice 值的范围很诡异？事实上，nice 值并不是表示优先级，而是表示优先级的修正数值，它与优先级（priority）的关系是这样的：priority(new) = priority(old) + nice。内核中，priority 的范围是 0~139，值越低，优先级越高，其中前面的 0~99 范围是提供给实时任务使用的，而 nice 值是映射到 100~139，这个范围是提供给普通任务用的，因此 nice 值调整的是普通任务的优先级。

在前面我们提到了，权重值与 nice 值的关系的，nice 值越低，权重值就越大，计算出来的 vruntime 就会越少，由于 CFS 算法调度的时候，就会优先选择 vruntime 少的任务进行执行，所以 nice 值越低，任务的优先级就越高。

我们可以在启动任务的时候，可以指定 nice 的值，比如将 mysqld 以 -3 优先级：  
```
$ nice -n -3 /usr/sbin/mysql
$ renice -10 -p pid
```

ice 调整的是普通任务的优先级，所以不管怎么缩小 nice 值，任务永远都是普通任务，如果某些任务要求实时性比较高，那么你可以考虑改变任务的优先级以及调度策略，使得它变成实时任务，比如：
```
# 修改调度策略为SCHED_FIFI，优先级1
$ chrf -f 1 -p 1996
```


## 6. 软中断

### 6.1 什么是中断
- 在计算机中，中断是用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核的中断处理程序来响应请求
- 操作系统收到中断请求后打断其他进程的运行，所以在中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少正常进程运行调度影响
- 中断在响应处理程序时会【临时关闭中断】，意味着如果当前中断程序没有执行完，系统的其他中断就无法响应，可能中断丢失，所以中断程序要尽快完成

### 6.2 软中断
Linux为了解决中断处理程序执行过长的和中断丢失的问题，将中断分为两个阶段，分别是【上半部分和下半部分】
- 上半部分用来快速处理中断，一般会暂时关闭中断请求，主要负责跟硬件紧密相关或者时间敏感的事情
- 下半部分用来处理上半部分未完成的工作，一般以【内核线程】的方式运行
例如：
    - 网卡收到网络包后，通过硬件中断通知内核有新的数据到了，于是内核会调用对应的中断处理程序来响应事件，这个事件也分为上半部分和下半部分
    - 上半部分做到快速处理，所以只需要吧数据读到内存中，然后更新硬件寄存器的状态，如吧状态更新为表示数据已经读到内存的状态
    - 接着内核触发一个软中断，把一些处理比较耗时复杂的事情交给【软中断处理程序】去做，即中断的下半部分，其主要需要从内存中找到网络数据，按照网络协议进行逐层解析和处理，送给应用程序
因此，中断处理程序的上半部分和下半部分可以理解为：
- 上半部分直接处理硬件请求，也就是硬中断，负责耗时断的事情
- 下半部分由内核触发，也就是软中断，负责上半部分未完成的工作，通常是耗时长的工作
上下部分的区别：
- 上半部分是硬中断，会打断CPU执行任务
- 下半部分是内核线程，每一个CPU都对应一个软中断内核线程，名字通常为【ksofttirqd/CPU编号】
软中断不只是包括硬件设备中断处理程序的下半部分，一些内核自定义的事件也属于软中断，比如内核调度等，rcu锁等

### 6.3 系统由哪些软中断
- 在Linux中，通过查看`/proc/softtirqs`的内容知晓【软中断】的运行情况，以及`/proc/interrupts`的内容来知晓【硬中断】的运行情况
- NET_RX 表示网络接收中断，NET_TX 表示网络发送中断、TIMER 表示定时中断、RCU 表示 RCU 锁中断、SCHED 表示内核调度中断
- 要注意同一种类型的软中断在不同 CPU 的分布情况，正常情况下，同一种中断在不同 CPU 上的累计次数相差不多，
- 这些数值是系统运行以来的累计中断次数，数值的大小没什么参考意义，但是系统的中断次数的变化速率才是我们要关注的，我们可以使用 watch -d cat /proc/softirqs 命令查看中断次数的变化速率

### 6.4 如何定位软中断CPU使用率过高的问题
top命令后按1 可以查看软中断情况
```
top - 21:40:54 up 32 days,  3:06,  0 users,  load average: 0.05, 0.05, 0.02
Tasks:  97 total,   3 running,  94 sleeping,   0 stopped,   0 zombie
%Cpu0  :  2.7 us,  1.7 sy,  0.0 ni, 94.3 id,  0.0 wa,  1.0 hi,  0.3 si,  0.0 st
MiB Mem :   1826.7 total,    131.6 free,    352.5 used,   1342.6 buff/cache
MiB Swap:      0.0 total,      0.0 free,      0.0 used.   1295.9 avail Mem 
```
上图中的si，就是 CPU 在软中断上的使用率，而且可以发现，每个 CPU 使用率都不高

另外，也可以看到 CPU 使用率最高的进程也是软中断 ksoftirqd，因此可以认为此时系统的开销主要来源于软中断。

如果要知道是哪种软中断类型导致的，我们可以使用 watch -d cat /proc/softirqs 命令查看每个软中断类型的中断次数的变化速率。

一般对于网络 I/O 比较高的 Web 服务器，NET_RX 网络接收中断的变化速率相比其他中断类型快很多。

如果发现 NET_RX 网络接收中断次数的变化速率过快，接下来就可以使用 sar -n DEV 查看网卡的网络包接收速率情况，然后分析是哪个网卡有大量的网络包进来。

接着，在通过 tcpdump 抓包，分析这些包的来源，如果是非法的地址，可以考虑加防火墙，如果是正常流量，则要考虑硬件升级等。

## 7. 数字的表示
### 7.1 整数的表示
- 无符号整数：十进制转换成二进制
- 有符号整数：最高位为符号位，为正数时，数值直接十进制转换成二进制，为复数时，十进制转换成二进制然后取反加一（补码），这样方便数值计算
- 小数：IEEE浮点数：符号位+指数位+尾数